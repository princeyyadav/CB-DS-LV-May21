{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4490b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cc178451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    \n",
    "    def __init__(self, ksize, filters, input_shape, activation, stride=1, padding=0):\n",
    "        self.ksize = ksize\n",
    "        self.filters = filters # no. of kernels in a layer -> no. of channels in each output\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.input_shape = input_shape # to decide no. of channels in the kernel\n",
    "        self.channels = input_shape[-1]\n",
    "        self.activation = activation\n",
    "        self.kernels = []\n",
    "        for i in range(self.filters):\n",
    "            k = np.random.randn(ksize, ksize, self.channels)\n",
    "            self.kernels.append(k)\n",
    "        self.bias = np.random.randn(1,self.filters)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _rotate(inp):\n",
    "        assert len(inp.shape)==4, f\"No. of dim in inp not equal to 4, got {inp.shape}\"\n",
    "        return np.flip(inp, axis=(1,2))\n",
    "\n",
    "    @staticmethod\n",
    "    def _convolution_op_helper(inp, kernel, stride=1):\n",
    "        # inp shape -> 4 dim\n",
    "        assert len(inp.shape)==4, f\"No. of dim in inp not equal to 4, got {inp.shape}\"\n",
    "        # kernel shouldhave 4 dim\n",
    "        assert len(kernel.shape)==4, f\"No. of dim in kernel not equal to 4, got {kernel.shape}\"\n",
    "\n",
    "        # no. of chanels in kernel and that in inp it should be same\n",
    "        assert inp.shape[-1] == kernel.shape[-1], f\"Mismatch in no. of channels in inp and kernel, got inp {inp.shape[-1]}, kernel {kernel.shape[-1]}\"\n",
    "        # non-square kernels are not allowed\n",
    "        assert kernel.shape[1] == kernel.shape[2], f\"dim 0 of kernel doesn't match dim 1, got {kernel.shape}\"\n",
    "        # inp shape square\n",
    "        assert inp.shape[1]>=kernel.shape[1] and inp.shape[2]>=kernel.shape[2], f\"Inp map dim(1,2) < kernel dim(1,2), got inp map dim 1, 2 {inp.shape[1:-1]}, kernel dim 1,2 {kernel.shape[1:-1]}\"\n",
    "\n",
    "        # flip the kernel\n",
    "        kernel = Conv2D._rotate(kernel)\n",
    "\n",
    "        oup = []\n",
    "        start_rloc = 0\n",
    "        end_rloc = kernel.shape[1]\n",
    "        while end_rloc <= inp.shape[1]:\n",
    "            output = []\n",
    "            start_cloc = 0\n",
    "            end_cloc = kernel.shape[2]\n",
    "            while end_cloc <= inp.shape[2]:\n",
    "                conv = (inp[:,start_rloc:end_rloc, start_cloc:end_cloc]*kernel).sum(axis=(1,2,3))\n",
    "                output.append(conv)\n",
    "\n",
    "                start_cloc += stride\n",
    "                end_cloc += stride\n",
    "            oup.append(output)\n",
    "            start_rloc += stride\n",
    "            end_rloc += stride\n",
    "        return np.moveaxis(oup, -1, 0)\n",
    "    \n",
    "    def _convolution_op(self, inp):\n",
    "        output = []\n",
    "        for kernel in self.kernels:\n",
    "            o = Conv2D._convolution_op_helper(inp, np.expand_dims(kernel, axis=0), self.stride)\n",
    "            output.append(o)\n",
    "        return np.stack(output, axis=-1)\n",
    "            \n",
    "    @staticmethod\n",
    "    def _pad(inp, pad_width):   \n",
    "        assert len(inp.shape)==4, f\"No. of dim in inp not equal to 4, got {inp.shape}\"\n",
    "        return np.pad(inp, ((0,0), (pad_width,pad_width), (pad_width,pad_width), (0,0)))\n",
    "\n",
    "    @staticmethod\n",
    "    def _inside_pad(inp, pad_width):\n",
    "        assert len(inp.shape)==4, f\"No. of dim in inp not equal to 4, got {inp.shape}\"\n",
    "        ix = np.repeat(np.arange(1, inp.shape[1]), pad_width)\n",
    "        inp = np.insert(inp, ix, 0, axis=1)\n",
    "        return np.insert(inp, ix, 0, axis=2)\n",
    "        \n",
    "\n",
    "    def eval(self, X):\n",
    "        o_ = self._convolution_op(X) + self.bias\n",
    "        return self.activation(o_)\n",
    "\n",
    "    def grad_activation(self, X): #pqrs\n",
    "        o_ = self._convolution_op(X) + self.bias # shape: m, h, w, c; eg (50, 3,3,2)\n",
    "        m, h, w, c = o_.shape # (50, 2,2, 5)\n",
    "        do_do_ = self.activation.grad_input(o_.reshape(m, h*c*w)) # shape of do_do-: (50, 20, 20)\n",
    "        return np.diagonal(do_do_, axis1=1, axis2=2).reshape(o_.shape)\n",
    "    \n",
    "    \n",
    "    def gradient_dict(self, X):\n",
    "        g = {}\n",
    "        g['activation'] = self.grad_activation(X) # do_do_\n",
    "        g['input'] = Conv2D._rotate(X) # flipped version of my input\n",
    "        return g\n",
    "        \n",
    "    def grad_input(self, X):\n",
    "        g1 = self.activation.grad_input( self.dot(X) )\n",
    "        g2 = self.dot.grad_input(X)\n",
    "        return np.einsum('mij,mjk->mik', g1, g2)\n",
    "\n",
    "    def grad_parameters(self, X):\n",
    "        da_dI = self.activation.grad_input(self.dot(X))\n",
    "        dI_dw = self.dot.grad_w(X)\n",
    "        da_dw = np.einsum('mij,mjkl->mikl', da_dI, dI_dw)\n",
    "\n",
    "        dI_db = self.dot.grad_b(X)\n",
    "        # print(da_dI.shape, dI_dw.shape, dI_db.shape)\n",
    "        da_db = np.einsum('mij,mjk->mik',  da_dI, dI_db)\n",
    "        return da_dw, da_db\n",
    "\n",
    "    def backprop_grad(self, grad_loss, grad): # abcd\n",
    "        # to find dL_dwi and dL_dbi, we need dL_do and do_do_. \n",
    "        \n",
    "        \"\"\"grad: dictionary, keys: activation, input\"\"\"\n",
    "        do_do_ = grad['activation'] # pqrs\n",
    "        ##################################\n",
    "        #                                #\n",
    "        #          dL_dbi                #\n",
    "        #                                #\n",
    "        ##################################\n",
    "    \n",
    "        dL_do_ = grad_loss * do_do_\n",
    "        dL_dbi = []\n",
    "        for c in range(dL_do_.shape[-1]):\n",
    "            b = dL_do_[:,:,:,c].sum(axis =(1, 2, 0))\n",
    "            dL_dbi.append(b)\n",
    "        dL_dbi = np.array(dL_dbi).reshape(1,-1)\n",
    "        \n",
    "        ##################################\n",
    "        #                                #\n",
    "        #          dL_dwi                #\n",
    "        #                                #\n",
    "        ##################################\n",
    "        kernels = Conv2D._inside_pad(dL_do_, self.stride-1) # abcd*pqrs -> act as a kernel while computing dL_dwi\n",
    "        inps = g['input'] \n",
    "        dL_dwi = [] # len should be same no. of filters in this layer\n",
    "        for i in range(dL_do_.shape[-1]):\n",
    "            kernel = kernels[:,:,:,i]\n",
    "            dwi = []\n",
    "            for j in range(inps.shape[-1]):\n",
    "                inp = inps[...,j]\n",
    "                conv = Conv2D._convolution_op_helper(np.expand_dims(inp,axis=-1) , np.expand_dims(kernel, axis=-1))\n",
    "                dwi.append(conv)\n",
    "            dwi = np.transpose(np.array(dwi), (1,0,2,3)).sum(axis=0)\n",
    "            dL_dwi.append(dwi)\n",
    "            \n",
    "        ##################################\n",
    "        #                                #\n",
    "        #          dL_dI                 #\n",
    "        #                                #\n",
    "        ##################################\n",
    "        inps = Con2D._pad(kernels, self.ksize-1)\n",
    "        kernels = self.kernels\n",
    "        dL_dI = []\n",
    "        for i in range(inps.shape[-1]):\n",
    "            ## ith channel of jth kernel needs to convolve with jth channel of inp \n",
    "            kernel = [self.kernels[...,i] for j in range(len(self.kernels))]\n",
    "        \n",
    "        \n",
    "        return dL_dwi, dL_dbi\n",
    "        \n",
    "        \n",
    "        \n",
    "#         return dL_dwi, dL_dbi, grad_loss\n",
    "        \n",
    "    def update(self, grad, optimizer):\n",
    "        \"\"\" grad: (dL_dwi, dL_dbi)\"\"\"\n",
    "        self.dot.W = optimizer.minimize(self.dot.W, grad[0])\n",
    "        self.dot.b = optimizer.minimize(self.dot.b, grad[1])\n",
    "        \n",
    "    def get_parameter_shape(self):\n",
    "        return self.dot.get_parameter_shape()\n",
    "    \n",
    "    def get_output_shape(self):\n",
    "        m, n, k, p, s = self.input_shape[1], input_shape[2], self.ksize, self.padding, self.stride\n",
    "        return (m-k+(2*p)//s)+1, (n-k+(2*p)//s)+1\n",
    "    \n",
    "    def get_total_parameters(self):\n",
    "        return np.prod((len(self.kernels), *self.kernels[0].shape)) + np.prod(self.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b4ece9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.ones((50, 4,4, 3)) # 50, 48\n",
    "c = Conv2D(ksize=3, filters=5, input_shape=inp.shape, activation=Sigmoid(), stride=1, padding=0)\n",
    "o = c._convolution_op(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3f0a7eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2, 2, 5)\n"
     ]
    }
   ],
   "source": [
    "print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = [self.kernels[j][...,i] for j in range(len(self.kernels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6987d5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['activation', 'input'])\n",
      "[[ 44.45763092 -17.93619947 -57.60791794  23.18264171   5.17880632]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = c.gradient_dict(inp)\n",
    "print(g.keys())\n",
    "dw, db = c.backprop_grad(o, g)\n",
    "print(db)\n",
    "db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8edc10d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3)\n",
      "(3, 3, 3)\n",
      "(3, 3, 3)\n",
      "(3, 3, 3)\n",
      "(3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "len(dw)\n",
    "for dki in dw:\n",
    "    print(dki.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76b151f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 2, 2, 5), (50, 4, 4, 3))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g['activation'].shape, g['input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79258ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2, 2, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_do_ = c.grad_activation(inp)\n",
    "do_do_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e2f78db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 20, 20)\n",
      "(50, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 2, 2, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = np.identity(20)\n",
    "o = np.transpose(np.stack([I]*50, axis=1), (1, 0, 2))\n",
    "print(o.shape)\n",
    "# I\n",
    "o[0, :,:]\n",
    "a = np.diagonal(o, axis1=1, axis2=2)\n",
    "print(a.shape)\n",
    "a.reshape((50, 2,2,5)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1a8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.eval(X)\n",
    "\n",
    "    def eval(self, X):\n",
    "        return 1/((np.e**-X) + 1)\n",
    "\n",
    "    def grad_input(self, X):\n",
    "        I = np.identity(X.shape[1])\n",
    "        b = self.eval(X)*(1-self.eval(X)) # same shape as X\n",
    "        return np.einsum('ij,mi->mij', I, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad2876bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.ones((10, 10,10, 3))\n",
    "l1 = Conv2D(ksize=5, filters=2, input_shape=inp.shape, activation=Sigmoid(), stride=1, padding=0)\n",
    "o = l1.eval(inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "daf6d880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6, 6, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a98895cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2, 2, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = Conv2D(ksize=5, filters=2, input_shape=o.shape, activation=Sigmoid(), stride=1, padding=0)\n",
    "l2.eval(o).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac4227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
