{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a4490b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc178451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    \n",
    "    def __init__(self, ksize, filters, input_size, activation, stride=1, padding=0):\n",
    "        if input_size[0] <= 0 or input_size[1] <= 0:\n",
    "            raise ValueError(f\"Input image size is invalid, got {input_size}\")\n",
    "        self.ksize = ksize\n",
    "        self.filters = filters # no. of kernels in a layer -> no. of channels in each output\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.input_size = input_size # to decide no. of channels in the kernel\n",
    "        self.channels = input_size[-1]\n",
    "        self.activation = activation\n",
    "        self.kernels = []\n",
    "        for i in range(self.filters):\n",
    "            k = np.random.randn(ksize, ksize, self.channels)\n",
    "            self.kernels.append(k)\n",
    "        self.bias = np.random.randn(1,self.filters)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _rotate(inp):\n",
    "        assert len(inp.shape)==4, f\"No. of dim in inp not equal to 4, got {inp.shape}\"\n",
    "        return np.flip(inp, axis=(1,2))\n",
    "\n",
    "    @staticmethod\n",
    "    def _convolution_op_helper(inp, kernel, stride=1):\n",
    "        # inp shape -> 4 dim\n",
    "        assert len(inp.shape)==4, f\"No. of dim in inp not equal to 4, got {inp.shape}\"\n",
    "        # kernel shouldhave 4 dim\n",
    "        assert len(kernel.shape)==4, f\"No. of dim in kernel not equal to 4, got {kernel.shape}\"\n",
    "\n",
    "        # no. of chanels in kernel and that in inp it should be same\n",
    "        assert inp.shape[-1] == kernel.shape[-1], f\"Mismatch in no. of channels in inp and kernel, got inp {inp.shape[-1]}, kernel {kernel.shape[-1]}\"\n",
    "        # non-square kernels are not allowed\n",
    "        assert kernel.shape[1] == kernel.shape[2], f\"dim 0 of kernel doesn't match dim 1, got {kernel.shape}\"\n",
    "        # inp shape square\n",
    "        assert inp.shape[1]>=kernel.shape[1] and inp.shape[2]>=kernel.shape[2], f\"Inp map dim(1,2) < kernel dim(1,2), got inp map dim 1, 2 {inp.shape[1:-1]}, kernel dim 1,2 {kernel.shape[1:-1]}\"\n",
    "\n",
    "        # flip the kernel\n",
    "        kernel = Conv2D._rotate(kernel)\n",
    "\n",
    "        oup = []\n",
    "        start_rloc = 0\n",
    "        end_rloc = kernel.shape[1]\n",
    "        while end_rloc <= inp.shape[1]:\n",
    "            output = []\n",
    "            start_cloc = 0\n",
    "            end_cloc = kernel.shape[2]\n",
    "            while end_cloc <= inp.shape[2]:\n",
    "                conv = (inp[:,start_rloc:end_rloc, start_cloc:end_cloc]*kernel).sum(axis=(1,2,3))\n",
    "                output.append(conv)\n",
    "\n",
    "                start_cloc += stride\n",
    "                end_cloc += stride\n",
    "            oup.append(output)\n",
    "            start_rloc += stride\n",
    "            end_rloc += stride\n",
    "        return np.moveaxis(oup, -1, 0)\n",
    "    \n",
    "    def _convolution_op(self, inp):\n",
    "        output = []\n",
    "        for kernel in self.kernels:\n",
    "            o = Conv2D._convolution_op_helper(inp, np.expand_dims(kernel, axis=0), self.stride)\n",
    "            output.append(o)\n",
    "        output = np.stack(output, axis=-1)\n",
    "        return output\n",
    "    \n",
    "    def _pad_grad_I(self, grad_I):\n",
    "        return np.pad(grad_I, [(0, 0), (0, self.input_size[0] - grad_I.shape[1]), (0, self.input_size[1] - grad_I.shape[2]), (0,0)])\n",
    "            \n",
    "    @staticmethod\n",
    "    def _pad(inp, pad_width):   \n",
    "        assert len(inp.shape)==4, f\"No. of dim in inp not equal to 4, got {inp.shape}\"\n",
    "        return np.pad(inp, ((0,0), (pad_width,pad_width), (pad_width,pad_width), (0,0)))\n",
    "\n",
    "    @staticmethod\n",
    "    def _inside_pad(inp, pad_width):\n",
    "        assert len(inp.shape)==4, f\"No. of dim in inp not equal to 4, got {inp.shape}\"\n",
    "        ix = np.repeat(np.arange(1, inp.shape[1]), pad_width)\n",
    "        inp = np.insert(inp, ix, 0, axis=1)\n",
    "        return np.insert(inp, ix, 0, axis=2)\n",
    "        \n",
    "\n",
    "    def eval(self, X):\n",
    "        o_ = self._convolution_op(X) + self.bias\n",
    "        return self.activation(o_)\n",
    "\n",
    "    def grad_activation(self, X): #pqrs\n",
    "        o_ = self._convolution_op(X) + self.bias # shape: m, h, w, c; eg (50, 3,3,2)\n",
    "        m, h, w, c = o_.shape # (50, 2,2, 5)\n",
    "        do_do_ = self.activation.grad_input(o_.reshape(m, h*c*w)) # shape of do_do-: (50, 20, 20)\n",
    "        return np.diagonal(do_do_, axis1=1, axis2=2).reshape(o_.shape)\n",
    "    \n",
    "    \n",
    "    def gradient_dict(self, X):\n",
    "        g = {}\n",
    "        g['activation'] = self.grad_activation(X) # do_do_\n",
    "        g['input'] = Conv2D._rotate(X) # flipped version of my input\n",
    "        return g\n",
    "        \n",
    "    def grad_input(self, X):\n",
    "        pass\n",
    "\n",
    "    def backprop_grad(self, grad_loss, grad): # abcd\n",
    "        # to find dL_dwi and dL_dbi, we need dL_do and do_do_. \n",
    "        \n",
    "        \"\"\"grad: dictionary, keys: activation, input\"\"\"\n",
    "        do_do_ = grad['activation'] # pqrs\n",
    "        ##################################\n",
    "        #                                #\n",
    "        #          dL_dbi                #\n",
    "        #                                #\n",
    "        ##################################\n",
    "        b, h, w, c = grad_loss.shape\n",
    "        dL_do_ = grad_loss * do_do_\n",
    "        dL_dbi = []\n",
    "        for c in range(dL_do_.shape[-1]):\n",
    "            b = dL_do_[:,:,:,c].sum(axis =(1, 2, 0))\n",
    "            dL_dbi.append(b)\n",
    "        dL_dbi = np.array(dL_dbi).reshape(1,-1)\n",
    "        \n",
    "        ##################################\n",
    "        #                                #\n",
    "        #          dL_dwi                #\n",
    "        #                                #\n",
    "        ##################################\n",
    "        kernels = Conv2D._inside_pad(dL_do_, self.stride-1) # abcd*pqrs -> act as a kernel while computing dL_dwi\n",
    "        inps = grad['input'] \n",
    "        dL_dwi = [] # len should be same no. of filters in this layer\n",
    "        for i in range(dL_do_.shape[-1]):\n",
    "            kernel = kernels[:,:,:,i]\n",
    "            dwi = []\n",
    "            for j in range(inps.shape[-1]):\n",
    "                inp = inps[...,j]\n",
    "                conv = Conv2D._convolution_op_helper(np.expand_dims(inp,axis=-1) , np.expand_dims(kernel, axis=-1))\n",
    "                dwi.append(conv)\n",
    "            dwi = np.transpose(np.array(dwi), (1,0,2,3)).sum(axis=0)\n",
    "            dwi = np.transpose(dwi, (1,2,0)) \n",
    "            dL_dwi.append(dwi)\n",
    "            \n",
    "        ##################################\n",
    "        #                                #\n",
    "        #          dL_dI                 #\n",
    "        #                                #\n",
    "        ##################################\n",
    "        inps = Conv2D._pad(kernels, self.ksize-1)\n",
    "        kernels = self.kernels\n",
    "        dL_dI = []\n",
    "        for i in range(self.input_size[-1]):\n",
    "            ## ith channel of jth kernel needs to convolve with jth channel of inp \n",
    "            kernel = [self.kernels[j][...,i] for j in range(len(self.kernels))]\n",
    "#             kernel = []\n",
    "#             for j in range(len(self.kernels)):\n",
    "#                 kernel.append(self.kernels[j][...,i])\n",
    "            kernel = np.stack(kernel, axis=-1) # 3,3,5\n",
    "            conv = Conv2D._convolution_op_helper(inps, np.expand_dims(kernel, axis=0))\n",
    "            dL_dI.append(conv)\n",
    "        dL_dI = np.stack(dL_dI, axis=-1)\n",
    "        \n",
    "        return dL_dwi, dL_dbi, dL_dI\n",
    "        \n",
    "    def update(self, grad, optimizer):\n",
    "        \"\"\" grad: (dL_dwi, dL_dbi)\"\"\"\n",
    "        self.bias = optimizer.minimize(self.bias, grad[1])\n",
    "        for i in range(len(self.kernels)):\n",
    "            self.kernels[i] = optimizer.minimize(self.kernels[i], grad[0][i]) \n",
    "            \n",
    "    def get_parameter_shape(self):\n",
    "        return self.kernels[0].shape, self.bias.shape\n",
    "    \n",
    "    def get_output_size(self):\n",
    "        m, n, k, p, s = self.input_size[0], self.input_size[1], self.ksize, self.padding, self.stride\n",
    "        return ((m-k+(2*p))//s)+1, ((n-k+(2*p))//s)+1, self.filters\n",
    "    \n",
    "    def get_total_parameters(self):\n",
    "        return np.prod((len(self.kernels), *self.kernels[0].shape)) + np.prod(self.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1a8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.eval(X)\n",
    "\n",
    "    def eval(self, X):\n",
    "        return 1/((np.e**-X) + 1)\n",
    "\n",
    "    def grad_input(self, X):\n",
    "        I = np.identity(X.shape[1])\n",
    "        b = self.eval(X)*(1-self.eval(X)) # same shape as X\n",
    "        return np.einsum('ij,mi->mij', I, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aaf1212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        if input_size[0] <= 0 or input_size[1] <= 0:\n",
    "            raise ValueError(f\"Input image size is invalid, got {input_size}\")\n",
    "        self.h, self.w, self.c = input_size\n",
    "        \n",
    "    def eval(self, X):\n",
    "        return X.reshape(-1, self.h*self.w*self.c)\n",
    "    \n",
    "    \n",
    "    def gradient_dict(self, X):\n",
    "        return {}\n",
    "\n",
    "    def backprop_grad(self, grad_loss, grad): # abcd\n",
    "        return None, None, grad_loss[:, 0, :].reshape(-1, self.h, self.w, self.c)\n",
    "        \n",
    "    def update(self, grad, optimizer):\n",
    "        \"\"\" grad: (dL_dwi, dL_dbi)\"\"\"\n",
    "        pass\n",
    "        \n",
    "    def get_parameter_shape(self):\n",
    "        return (\"-\",\"-\")\n",
    "    \n",
    "    def get_output_size(self):\n",
    "        return (1,self.h*self.w*self.c)\n",
    "    \n",
    "    def get_total_parameters(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13dfc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"E://CB-DS-LV-May21//DS//NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af299340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from activation import Sigmoid\n",
    "from loss import BinaryCrossEntropy\n",
    "from optimizer import GradientDescentOptimizer\n",
    "from layer import Dense\n",
    "from model import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7b88d",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0cd2008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f7a880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a35de9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12665, 28, 28, 1) (12665, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train[(y_train==0) | (y_train==1)].reshape(-1, 28,28,1)/255\n",
    "y_train = y_train[(y_train==0) | (y_train==1)].reshape(-1,1)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cda329b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+------------+---------+--------------+------------------+\n",
      "| # | Layer Type |  W.shape   | b.shape | Output shape | Total parameters |\n",
      "+---+------------+------------+---------+--------------+------------------+\n",
      "| 1 |   Conv2D   | (5, 5, 1)  | (1, 20) | (24, 24, 20) |       520        |\n",
      "| 2 |   Conv2D   | (5, 5, 20) | (1, 10) | (20, 20, 10) |       5010       |\n",
      "| 3 |   Conv2D   | (3, 3, 10) | (1, 5)  | (18, 18, 5)  |       455        |\n",
      "| 4 |  Flatten   |     -      |    -    |  (1, 1620)   |        0         |\n",
      "| 5 |   Dense    | (1620, 1)  | (1, 1)  |    (1, 1)    |       1621       |\n",
      "+---+------------+------------+---------+--------------+------------------+\n",
      "Total no. of model parameters 7606\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(BinaryCrossEntropy())\n",
    "model.add(Conv2D, ksize=5, filters=20, input_size=(28,28,1), activation=Sigmoid(), stride=1, padding=0)\n",
    "model.add(Conv2D, ksize=5, filters=10, activation=Sigmoid(), stride=1, padding=0)\n",
    "model.add(Conv2D, ksize=3, filters=5, activation=Sigmoid(), stride=1, padding=0)\n",
    "model.add(Flatten)\n",
    "model.add(Dense, activation=Sigmoid(), units=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01c44e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1cfd5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(x_train[0:10])\n",
    "print(ypred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5014b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.10340371916185"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss(ypred, y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a399037f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Shape mismatch w shape (3, 3, 10) != grad shape (10, 3, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-391d8f552c42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE://CB-DS-LV-May21//DS//NN\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, epochs, optimizer, learning_rate, verbose, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                     \u001b[1;31m# ypred = self.predict(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE://CB-DS-LV-May21//DS//NN\\model.py\u001b[0m in \u001b[0;36mback_propagate\u001b[1;34m(self, grads, outputs, y)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# print(layer.__class__.__name__)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mdL_dwi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdL_dbi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdL_dwi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdL_dbi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-3db0b20a99ce>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, grad, optimizer)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_parameter_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE://CB-DS-LV-May21//DS//NN\\optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, w, grad)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"Shape mismatch w shape {w.shape} != grad shape {grad.shape}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Shape mismatch w shape (3, 3, 10) != grad shape (10, 3, 3)"
     ]
    }
   ],
   "source": [
    "model.fit(x_train[:10], y_train[:10], epochs=1, optimizer=GradientDescentOptimizer, learning_rate=0.005, verbose=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63118744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(x_train[0:10])\n",
    "print(ypred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "475e77fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.72658053446011"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss(ypred, y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b953204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
