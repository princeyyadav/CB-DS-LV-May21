{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32ce2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6997854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\\\\NN\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8535146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from activation import Sigmoid, ReLU\n",
    "from loss import BinaryCrossEntropy\n",
    "from optimizer import GradientDescentOptimizer\n",
    "from layer import Dense\n",
    "from model import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a0792a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNN:\n",
    "\n",
    "    def __init__(self, input_size, output_activation, output_units, hidden_units):\n",
    "        \"\"\"\n",
    "        input_size: dimension of 1 sample: (timestep, features)\n",
    "        activation: activation of output layer\n",
    "        output_units: no. of neurons in output layer\n",
    "        hidden_units: no. of neurons in hidden layer\n",
    "        \"\"\"\n",
    "        if isinstance(input_size, tuple) and len(input_size)!=2:\n",
    "            raise ValueError(f\"Incompatible input shape, got {input_size}\")\n",
    "            \n",
    "        self.output_activation = output_activation\n",
    "        self.hidden_units = hidden_units\n",
    "        self.output_units = output_units\n",
    "        self.input_units = input_size[1] # f\n",
    "        self.timestep = input_size[0]\n",
    "        \n",
    "        self.hidden_layer = Dense(units=hidden_units, activation=ReLU(), input_size=self.hidden_units+self.input_units)\n",
    "        self.output_layer = Dense(units=output_units, activation=self.output_activation, input_size=hidden_units)\n",
    "        \n",
    "        \n",
    "    def eval(self, X, start_sequence=None): # m,t,f\n",
    "        ht_1 = np.zeros(( X.shape[0], self.hidden_units))\n",
    "        if start_sequence != None:\n",
    "            ht_1 = start_sequence\n",
    "        y = np.empty((X.shape[0], self.timestep, self.output_units)) # m, t, output_units\n",
    "        for i in range(self.timestep):\n",
    "            xt_stacked = np.concatenate([X[:,i,:],ht_1], axis=1)\n",
    "            ht = self.hidden_layer.eval(xt_stacked)\n",
    "            y[:,i,:] = self.output_layer.eval(ht)\n",
    "        return y\n",
    "    \n",
    "    def get_parameter_shape(self):\n",
    "        ## wh, wo, bh, bo\n",
    "        \"\"\" returns shape of Wh, Wf\"\"\"\n",
    "        wh_shape, bh_shape = self.hidden_layer.dot.get_parameter_shape()\n",
    "        wo_shape, bo_shape = self.output_layer.dot.get_parameter_shape()\n",
    "        return wh_shape, wo_shape\n",
    "    \n",
    "    def get_total_parameters(self):\n",
    "        wh_shape, bh_shape = self.hidden_layer.dot.get_parameter_shape()\n",
    "        wo_shape, bo_shape = self.output_layer.dot.get_parameter_shape()\n",
    "        return np.prod(wh_shape) + np.prod(bh_shape) + np.prod(wo_shape) + np.prod(bo_shape)\n",
    "\n",
    "    def get_output_size(self):\n",
    "        \"\"\" returns output shape corresponding to just 1 sample\"\"\"\n",
    "        return self.timestep, self.output_units\n",
    "\n",
    "    def grad_parameters_t(self, xt, ht_1):\n",
    "        \"\"\" computes dyt_dwo, dyt_dbo, dyt_dwh, dyt_dbh \"\"\"\n",
    "        xt_stacked = np.concatenate([xt,ht_1], axis=1)\n",
    "        ht = self.hidden_layer.eval(xt_stacked)\n",
    "        dyt_dwo, dyt_dbo = self.output_layer.grad_parameters(ht)\n",
    "        dyt_dht = self.output_layer.grad_input(ht)\n",
    "        \n",
    "        dht_dwh, dht_dbh = self.hidden_layer.grad_parameters(xt_stacked)\n",
    "        dyt_dwh = np.einsum('mij,mjkl->mikl', dyt_dht, dht_dwh)\n",
    "        dyt_dbh = np.einsum('mij,mjk->mik',  dyt_dht, dht_dbh)\n",
    "        return dyt_dwo, dyt_dbo, dyt_dwh, dyt_dbh, ht\n",
    "    \n",
    "    def grad_input_t(self, xt, ht_1):\n",
    "        \"\"\" computes dyt_dxt, dyt_dht_1\"\"\"\n",
    "        xt_stacked = np.concatenate([xt,ht_1], axis=1)\n",
    "        ht = self.hidden_layer.eval(xt_stacked)\n",
    "        \n",
    "        dyt_dht = self.output_layer.grad_input(ht)\n",
    "        \n",
    "        dht_dxt_stacked = self.hidden_layer.grad_input(xt_stacked)\n",
    "        dht_dxt = dht_dxt_stacked[:,:,:self.input_units]\n",
    "        dht_dht_1 = dht_dxt_stacked[:,:,self.input_units:]\n",
    "        \n",
    "        dyt_dxt_stacked = np.einsum('mij,mjk->mik', dyt_dht, dht_dxt_stacked)\n",
    "        \n",
    "        dyt_dxt = dyt_dxt_stacked[:,:,:self.input_units] \n",
    "        dyt_dht_1 = dyt_dxt_stacked[:,:,self.input_units:] \n",
    "        return dyt_dxt, dyt_dht_1, dht_dht_1, dht_dxt, ht\n",
    "    \n",
    "    def grad_input(self, X, start_sequence=None):\n",
    "        \"\"\" computes dY_dX: grad of output wrt input for all timesteps/ cells \"\"\"\n",
    "        m, t = X.shape[0], X.shape[1]\n",
    "        o_u, i_u = self.output_units, self.input_units\n",
    "        \n",
    "        ht_1 = np.zeros(( m, self.hidden_units))\n",
    "        if start_sequence != None:\n",
    "            ht_1 = start_sequence\n",
    "            \n",
    "        dY_dX = np.zeros((m, t, t, o_u, i_u))\n",
    "        \n",
    "        grad_across_time = {}\n",
    "        for i in range(t):\n",
    "            xt = X[:,i,:]\n",
    "            \n",
    "            dyt_dxt, dyt_dht_1, dht_dht_1, dht_dxt, ht_1 = self.grad_input_t(xt, ht_1)\n",
    "            dY_dX[:,i,i] = dyt_dxt\n",
    "            \n",
    "            grad_across_time[i] = {}\n",
    "            grad_across_time[i]['dht_dht_1'] = dht_dht_1\n",
    "            grad_across_time[i]['dht_dxt'] = dht_dxt\n",
    "            \n",
    "            for j in range(i-1, -1, -1):\n",
    "                dY_dX[:,i,j,:,:] = np.einsum('mij,mjk->mik', dyt_dht_1, grad_across_time[j]['dht_dxt'])\n",
    "                dyt_dht_1 = np.einsum('mij,mjk->mik', dyt_dht_1, grad_across_time[j]['dht_dht_1'])\n",
    "        return dY_dX\n",
    "\n",
    "    def grad_parameters(self, X, start_sequence):\n",
    "        ht_1 = np.zeros(( m, self.hidden_units))\n",
    "        if start_sequence != None:\n",
    "            ht_1 = start_sequence\n",
    "        \n",
    "        for i in range(self.timestep):\n",
    "            xt = X[:,i,:]\n",
    "            \n",
    "            dyt_dwo, dyt_dbo, dyt_dwh, dyt_dbh = self.grad_parameters_t()\n",
    "#             to be done\n",
    "            \n",
    "        \n",
    "        return da_dw, da_db\n",
    "\n",
    "    def backprop_grad(self, grad_loss, grad):\n",
    "        dL_dwi = np.einsum('mij,mjkl->mikl', grad_loss, grad['w']).sum(axis=0)[0]\n",
    "        dL_dbi = np.einsum('mij,mjk->mik', grad_loss, grad['b']).sum(axis=0)\n",
    "        grad_loss = np.einsum('mij,mjk->mik', grad_loss, grad['input'])\n",
    "        return dL_dwi, dL_dbi, grad_loss\n",
    "        \n",
    "    def gradient_dict(self, output):\n",
    "        g = {}\n",
    "        g['input'] = self.grad_input(output)\n",
    "        g['w'], g['b'] = self.grad_parameters(output)\n",
    "        return g\n",
    "\n",
    "    def update(self, grad, optimizer):\n",
    "        \"\"\" grad: (dL_dwi, dL_dbi)\"\"\"\n",
    "        self.dot.W = optimizer.minimize(self.dot.W, grad[0])\n",
    "        self.dot.b = optimizer.minimize(self.dot.b, grad[1])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e83bf946",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(2,5,6) # m,t,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a2633d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3288aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = BasicRNN(input_size=X.shape[1:], output_activation=Sigmoid(), output_units=3, hidden_units=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "75297a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 5, 3, 6)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.grad_input(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "05687357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.eval(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "49a6d9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.get_total_parameters()\n",
    "# wh -> h_u + f, h_u -> (4+6, 4) -> 10,4 -> 40\n",
    "# bh -> (1,h_u) - > (1,4) -> 4\n",
    "# wo -> (h_u, o_u) -> (4,3) -> 12\n",
    "# bo -> (1,o_u) -> (1,3) -> 3\n",
    "# 40 + 4 + 12 + 3 = 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a92dbe60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 4), (4, 3))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.get_parameter_shape() # wh_shape, wo_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5117feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65f0345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(X):\n",
    "    x = X.copy()\n",
    "    x[x<0] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfbb6303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.         0.27948775 0.98570582 0.38136993 0.         0.        ]\n",
      "  [0.40027991 0.01333856 0.3616865  0.27387359 1.565782   1.91191395]\n",
      "  [1.53453606 0.         1.10038672 0.         0.         0.10829895]\n",
      "  [0.         0.83602428 0.46200109 0.         0.51585997 0.52166674]\n",
      "  [1.27018777 0.36442535 0.         0.         2.1994819  0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "ans = func(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8ed8d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.44005063, -0.39597992,  0.8269271 , -0.46858854,\n",
       "         -0.15871013,  1.2412698 ],\n",
       "        [-0.34501907,  1.91476221,  0.14398673, -0.238387  ,\n",
       "         -0.56056956,  0.70709831],\n",
       "        [-0.03690487,  1.51497133,  0.99664874, -1.13692055,\n",
       "         -0.54514179,  1.91404761],\n",
       "        [-0.18410903,  1.11430618, -0.48743262,  1.61321692,\n",
       "          0.85752629, -0.25828559],\n",
       "        [-0.12655564, -0.48302907, -1.69446662,  1.13701279,\n",
       "         -0.01144496, -2.26846502]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e633e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.        , -0.        ,  0.8269271 , -0.        ,\n",
       "         -0.        ,  1.2412698 ],\n",
       "        [-0.        ,  1.91476221,  0.14398673, -0.        ,\n",
       "         -0.        ,  0.70709831],\n",
       "        [-0.        ,  1.51497133,  0.99664874, -0.        ,\n",
       "         -0.        ,  1.91404761],\n",
       "        [-0.        ,  1.11430618, -0.        ,  1.61321692,\n",
       "          0.85752629, -0.        ],\n",
       "        [-0.        , -0.        , -0.        ,  1.13701279,\n",
       "         -0.        , -0.        ]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X>=0)*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ea874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
