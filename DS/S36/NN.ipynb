{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Session 36 \r\n",
    "Aug 20, 2021"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class Sigmoid:\r\n",
    "\r\n",
    "    def __call__(self, X):\r\n",
    "        return self.eval(X)\r\n",
    "\r\n",
    "    def eval(self, X):\r\n",
    "        return 1/((np.e**-X) + 1)\r\n",
    "\r\n",
    "    def grad_input(self, X):\r\n",
    "        return self.eval(X) * (1-self.eval(X))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "class Dot:\r\n",
    "\r\n",
    "    def __init__(self, input_size, units):\r\n",
    "        self.W = np.random.randn(input_size, units)\r\n",
    "        self.b = np.random.randn(1, units)\r\n",
    "\r\n",
    "    def __call__(self, X):\r\n",
    "        return self.eval(X)\r\n",
    "\r\n",
    "    def eval(self, X):\r\n",
    "        return X.dot(self.W) + self.b\r\n",
    "\r\n",
    "    def grad_input(self):\r\n",
    "        return self.w.T\r\n",
    "\r\n",
    "    def grad_w(self, X):\r\n",
    "        return X\r\n",
    "\r\n",
    "    def grad_b(self):\r\n",
    "        return np.identity(self.b.shape[1])\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "np.identity(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class Dense:\r\n",
    "\r\n",
    "    def __init__(self, input_size, activation, units):\r\n",
    "        \"\"\"\r\n",
    "        input_size: no. of neurons in previous layer\r\n",
    "        activation: some activation funtion\r\n",
    "        units: no. of neurons in current layer \r\n",
    "        \"\"\"\r\n",
    "        self.activation = activation\r\n",
    "        self.units = units\r\n",
    "        self.dot = Dot(input_size, units)\r\n",
    "\r\n",
    "    def eval(self, X):\r\n",
    "        return self.activation( self.dot(X))\r\n",
    "\r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "class Sequential:\r\n",
    "\r\n",
    "    def __init__(self):\r\n",
    "        self.layers = []\r\n",
    "\r\n",
    "    def add(self, layer):\r\n",
    "        self.layers.append(layer)\r\n",
    "\r\n",
    "    def forward_propagation(self, X):\r\n",
    "        output = X\r\n",
    "        i = 1\r\n",
    "        for layer in self.layers:\r\n",
    "            inp_shape = output.shape\r\n",
    "            output = layer.eval(output)\r\n",
    "            print(f\"Layer {i}: input: {inp_shape} W{i}: {layer.dot.W.shape} b{i}: {layer.dot.b.shape} output: {output.shape}\")\r\n",
    "            i += 1\r\n",
    "        return output\r\n",
    "\r\n",
    "    def eval(self, X):\r\n",
    "        return self.forward_propagation(X)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "model = Sequential()\r\n",
    "model.add(Dense(input_size = 2, activation=Sigmoid(), units=2))\r\n",
    "model.add(Dense(input_size = 2, activation=Sigmoid(), units=2))\r\n",
    "model.add(Dense(input_size=2, activation=Sigmoid(), units=3))\r\n",
    "model.add(Dense(input_size = 3, activation=Sigmoid(), units=1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "X = np.random.randn(1,2)\r\n",
    "ypred = model.eval(X)\r\n",
    "print(ypred.shape)\r\n",
    "ypred"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Layer 1: input: (10, 2) W1: (2, 2) b1: (1, 2) output: (10, 2)\n",
      "Layer 2: input: (10, 2) W2: (2, 2) b2: (1, 2) output: (10, 2)\n",
      "Layer 3: input: (10, 2) W3: (2, 3) b3: (1, 3) output: (10, 3)\n",
      "Layer 4: input: (10, 3) W4: (3, 1) b4: (1, 1) output: (10, 1)\n",
      "(10, 1)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.85806129],\n",
       "       [0.85737002],\n",
       "       [0.85593053],\n",
       "       [0.85900398],\n",
       "       [0.85740431],\n",
       "       [0.85480002],\n",
       "       [0.85398956],\n",
       "       [0.85785693],\n",
       "       [0.85492803],\n",
       "       [0.8584702 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "d62006d1f3422635846181a997a61e8ec3049f797e5d7dfe0cd1bb84092b7c19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}